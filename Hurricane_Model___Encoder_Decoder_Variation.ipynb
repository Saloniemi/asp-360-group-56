{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ycpjI1ZGxvBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('stripped_storms.csv', header=None, skiprows = 1)\n",
        "# 258 unique hurricanes\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print(df[0].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiu2W9XvWHYi",
        "outputId": "4fd1ce40-c34f-4686-a660-318cd747ef76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Bonnie       273\n",
            "Bertha       261\n",
            "Dennis       244\n",
            "Florence     239\n",
            "Claudette    237\n",
            "Emily        236\n",
            "Alberto      233\n",
            "Josephine    231\n",
            "Helene       228\n",
            "Edouard      228\n",
            "Frances      215\n",
            "Danielle     214\n",
            "Earl         208\n",
            "Felix        206\n",
            "Lili         204\n",
            "Arlene       199\n",
            "Harvey       198\n",
            "Chris        198\n",
            "Danny        197\n",
            "Gabrielle    196\n",
            "Gordon       196\n",
            "Ana          189\n",
            "Erin         184\n",
            "Beryl        181\n",
            "Irene        176\n",
            "Leslie       175\n",
            "Ivan         175\n",
            "Ophelia      175\n",
            "Arthur       172\n",
            "Gert         171\n",
            "Chantal      171\n",
            "Debby        170\n",
            "Isaac        170\n",
            "Isidore      168\n",
            "Barry        165\n",
            "Cindy        164\n",
            "Karl         163\n",
            "Charley      163\n",
            "Maria        161\n",
            "Gustav       161\n",
            "Jeanne       158\n",
            "Humberto     158\n",
            "Henri        154\n",
            "Ernesto      152\n",
            "Jose         152\n",
            "Dean         148\n",
            "Lisa         144\n",
            "Gloria       144\n",
            "Jerry        138\n",
            "Bret         138\n",
            "Grace        135\n",
            "Kate         133\n",
            "Karen        132\n",
            "Floyd        131\n",
            "Kyle         127\n",
            "Nadine       127\n",
            "Alex         125\n",
            "Erika        124\n",
            "Otto         124\n",
            "Fay          124\n",
            "Fred         124\n",
            "Hermine      124\n",
            "Ida          122\n",
            "Dorian       121\n",
            "Hanna        121\n",
            "Allison      121\n",
            "Hortense     119\n",
            "Cristobal    115\n",
            "Noel         113\n",
            "Gaston       111\n",
            "Lee          111\n",
            "Nicole       110\n",
            "Bill         109\n",
            "Iris         109\n",
            "Dolly        107\n",
            "Bob          105\n",
            "Fran         104\n",
            "Georges      103\n",
            "Michael      102\n",
            "Nicholas     101\n",
            "Marco        100\n",
            "Philippe     100\n",
            "Lorenzo       99\n",
            "Fabian        97\n",
            "Isabel        94\n",
            "Larry         88\n",
            "Paulette      88\n",
            "Epsilon       84\n",
            "Julia         84\n",
            "Nate          84\n",
            "Melissa       82\n",
            "Olga          82\n",
            "Katia         82\n",
            "Joyce         79\n",
            "Marilyn       79\n",
            "Matthew       79\n",
            "Mitch         78\n",
            "Joaquin       76\n",
            "Laura         76\n",
            "Keith         74\n",
            "Delta         73\n",
            "Irma          72\n",
            "Franklin      71\n",
            "Katrina       70\n",
            "Frederic      68\n",
            "Andrew        68\n",
            "Odette        66\n",
            "Hugo          64\n",
            "Ike           62\n",
            "Gonzalo       62\n",
            "Igor          61\n",
            "Cesar         61\n",
            "Luis          61\n",
            "Zeta          61\n",
            "Sam           59\n",
            "Omar          59\n",
            "Eta           58\n",
            "Diana         58\n",
            "Klaus         58\n",
            "Rafael        56\n",
            "Roxanne       56\n",
            "David         55\n",
            "Fiona         55\n",
            "Tomas         54\n",
            "Gamma         54\n",
            "Wanda         54\n",
            "Sebastien     53\n",
            "Joan          53\n",
            "Beta          52\n",
            "Rina          52\n",
            "Juan          51\n",
            "Nana          50\n",
            "Kirk          50\n",
            "Gilbert       49\n",
            "Oscar         49\n",
            "Teddy         49\n",
            "Ingrid        48\n",
            "Ten           48\n",
            "Wilma         48\n",
            "Eloise        46\n",
            "Gladys        46\n",
            "Elena         46\n",
            "Sandy         45\n",
            "Allen         44\n",
            "Elsa          43\n",
            "Colin         40\n",
            "Lenny         39\n",
            "Opal          39\n",
            "Fifteen       39\n",
            "Pablo         38\n",
            "Isaias        36\n",
            "Paloma        36\n",
            "Rita          36\n",
            "Michelle      35\n",
            "Theta         33\n",
            "Caroline      33\n",
            "Eight         32\n",
            "Five          32\n",
            "AL031987      32\n",
            "Rene          32\n",
            "Amy           31\n",
            "Emmy          31\n",
            "Peter         31\n",
            "Two           30\n",
            "Richard       29\n",
            "Doris         29\n",
            "Tanya         29\n",
            "Sean          28\n",
            "Sally         28\n",
            "Clara         27\n",
            "Ella          27\n",
            "Iota          26\n",
            "AL081992      25\n",
            "Alicia        25\n",
            "Vicky         24\n",
            "Mindy         24\n",
            "Victor        22\n",
            "Rose          22\n",
            "AL121991      22\n",
            "Ian           21\n",
            "Don           21\n",
            "Paula         21\n",
            "Tony          20\n",
            "Anita         20\n",
            "Blanche       20\n",
            "Flossie       19\n",
            "Faye          19\n",
            "Cora          19\n",
            "Nine          19\n",
            "Belle         18\n",
            "AL141995      17\n",
            "Stan          17\n",
            "Wilfred       17\n",
            "Fernand       16\n",
            "Hope          16\n",
            "Juliet        16\n",
            "One           15\n",
            "Nestor        15\n",
            "Dorothy       15\n",
            "Vince         15\n",
            "Hallie        14\n",
            "Andrea        14\n",
            "Al202011      14\n",
            "AL042000      13\n",
            "Julian        13\n",
            "AL061988      13\n",
            "AL102004      13\n",
            "Bess          13\n",
            "AL022006      13\n",
            "AL121999      12\n",
            "Greta         12\n",
            "AL022000      12\n",
            "Kendra        11\n",
            "AL142002      11\n",
            "Patty         11\n",
            "Candice       11\n",
            "Alpha         11\n",
            "AL011993      11\n",
            "AL081994      10\n",
            "Frieda        10\n",
            "Dottie        10\n",
            "Evelyn        10\n",
            "Babe          10\n",
            "AL111999      10\n",
            "AL142003      10\n",
            "Imelda         9\n",
            "Four           9\n",
            "Nineteen       9\n",
            "Tammy          9\n",
            "Shary          9\n",
            "AL051994       9\n",
            "AL061995       9\n",
            "AL062003       8\n",
            "AL071999       8\n",
            "Sixteen        8\n",
            "AL031992       8\n",
            "AL061997       8\n",
            "Debra          7\n",
            "AL101994       7\n",
            "AL091994       7\n",
            "Holly          7\n",
            "AL072003       7\n",
            "AL041991       7\n",
            "AL092000       6\n",
            "AL021994       6\n",
            "Amelia         6\n",
            "AL101993       5\n",
            "Three          5\n",
            "Eleven         5\n",
            "AL021992       5\n",
            "AL072002       5\n",
            "AL101991       5\n",
            "AL022001       5\n",
            "AL022003       4\n",
            "AL021999       4\n",
            "AL012000       4\n",
            "AL092003       4\n",
            "AL092001       4\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('triplets.csv', header=None, skiprows = 1)\n",
        "\n",
        "df = df.sample(frac = 1, random_state= 42)\n",
        "\n",
        "data = []\n",
        "\n",
        "# Convert df dataframe to list of lists\n",
        "for index, row in df.iterrows():\n",
        "    data.append(row.tolist())\n",
        "\n",
        "# Convert list of lists to numpy array\n",
        "data = np.array(data)\n",
        "\n",
        "# Construct encoder, decoder input and target\n",
        "X_encoder = []\n",
        "X_decoder = []\n",
        "y_decoder = []\n",
        "\n",
        "# X_encode = everything in the row from 0 to row length - 6. Then, X_encode is separated into list of lists\n",
        "for i in range(len(data)):\n",
        "    X_encoder.append(data[i][:12])\n",
        "    X_decoder.append(data[i][6:])\n",
        "    y_decoder.append(list(data[i][9:12]) + list(data[i][15:18]))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_encoder = np.array(X_encoder).reshape(len(X_encoder), 2, 6)\n",
        "X_decoder = np.array(X_decoder).reshape(len(X_decoder), 2, 6)\n",
        "y_decoder = np.array(y_decoder).reshape(len(X_decoder), 2, 3)\n",
        "\n",
        "# split into training, validation, and data set\n",
        "\n",
        "print(\"X_encoder shape:\", X_encoder.shape)\n",
        "print(\"X_decoder shape:\", X_decoder.shape)\n",
        "print(\"y_decoder shape:\", y_decoder.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68xq_VwrxwqO",
        "outputId": "882aff01-41d2-4c4e-f70e-6540f336f9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_encoder shape: (18550, 2, 6)\n",
            "X_decoder shape: (18550, 2, 6)\n",
            "y_decoder shape: (18550, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and temp (validation + test) sets (60-40 split)\n",
        "X_encoder_train, X_encoder_temp, X_decoder_train, X_decoder_temp, y_decoder_train, y_decoder_temp = \\\n",
        "    train_test_split(X_encoder, X_decoder, y_decoder, test_size=0.4, shuffle=False)\n",
        "\n",
        "# Split temp into validation and test sets (50-50 split of the remaining 40%)\n",
        "X_encoder_val, X_encoder_test, X_decoder_val, X_decoder_test, y_decoder_val, y_decoder_test = \\\n",
        "    train_test_split(X_encoder_temp, X_decoder_temp, y_decoder_temp, test_size=0.5, shuffle=False)\n",
        "\n",
        "print(\"Training set shapes:\")\n",
        "print(\"X_encoder_train:\", X_encoder_train.shape)\n",
        "print(\"X_decoder_train:\", X_decoder_train.shape)\n",
        "print(\"y_decoder_train:\", y_decoder_train.shape)\n",
        "\n",
        "print(\"\\nValidation set shapes:\")\n",
        "print(\"X_encoder_val:\", X_encoder_val.shape)\n",
        "print(\"X_decoder_val:\", X_decoder_val.shape)\n",
        "print(\"y_decoder_val:\", y_decoder_val.shape)\n",
        "\n",
        "print(\"\\nTesting set shapes:\")\n",
        "print(\"X_encoder_test:\", X_encoder_test.shape)\n",
        "print(\"X_decoder_test:\", X_decoder_test.shape)\n",
        "print(\"y_decoder_test:\", y_decoder_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-pEG6yyVxX",
        "outputId": "07301474-f5ed-4d31-ff1c-e15422e3cb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shapes:\n",
            "X_encoder_train: (11130, 2, 6)\n",
            "X_decoder_train: (11130, 2, 6)\n",
            "y_decoder_train: (11130, 2, 3)\n",
            "\n",
            "Validation set shapes:\n",
            "X_encoder_val: (3710, 2, 6)\n",
            "X_decoder_val: (3710, 2, 6)\n",
            "y_decoder_val: (3710, 2, 3)\n",
            "\n",
            "Testing set shapes:\n",
            "X_encoder_test: (3710, 2, 6)\n",
            "X_decoder_test: (3710, 2, 6)\n",
            "y_decoder_test: (3710, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 6\n",
        "time_step = 2\n",
        "num_decoder_features = 3\n",
        "LSTM_hidden_dim = 64\n",
        "LSTM_cell_activation = 'tanh'\n",
        "LSTM_gate_activation = 'sigmoid'\n",
        "dense_activation = 'linear'\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'"
      ],
      "metadata": {
        "id": "2Y09LnxqXl-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def percentage_deviation(y_true, y_pred):\n",
        "    epsilon = K.epsilon()\n",
        "    percentage_dev = tf.reduce_mean(tf.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "    return percentage_dev"
      ],
      "metadata": {
        "id": "pqQSgm6DzsN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "UC9mMYKuV1OU",
        "outputId": "e271919a-b2b6-4958-c362-d12309c9e1d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m18,176\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                           │ \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),     │         \u001b[38;5;34m18,176\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,     │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
              "│                           │ \u001b[38;5;34m64\u001b[0m)]                   │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)        │            \u001b[38;5;34m195\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]                   │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,547\u001b[0m (142.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,547</span> (142.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,547\u001b[0m (142.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,547</span> (142.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_features = 6\n",
        "time_step = 2\n",
        "num_decoder_features = 3\n",
        "LSTM_hidden_dim = 64\n",
        "LSTM_cell_activation = 'tanh'\n",
        "LSTM_gate_activation = 'sigmoid'\n",
        "dense_activation = 'linear'\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "# Define the encoder\n",
        "encoder_inputs = Input(shape=(None, num_features))\n",
        "encoder_lstm = LSTM(LSTM_hidden_dim, return_state=True, activation = LSTM_cell_activation, recurrent_activation=LSTM_gate_activation)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Define the decoder\n",
        "decoder_inputs = Input(shape=(None, num_features))\n",
        "decoder_lstm = LSTM(LSTM_hidden_dim, return_sequences=True, return_state=True, activation = LSTM_cell_activation, recurrent_activation=LSTM_gate_activation)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_features, activation = dense_activation)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer, loss, metrics = [percentage_deviation])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# explain the input and output shape of each of the layers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data imputation model\n",
        "# loss function compare against all 6 points\n",
        "# more points per timestep (start with 10)\n",
        "# combine month date hour into one feature\n",
        "# look into TimeSeriesSplit\n",
        "# try the original model\n"
      ],
      "metadata": {
        "id": "GCuV00Oi6kcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit([X_encoder_train, X_decoder_train], y_decoder_train, batch_size, epochs, validation_data=([X_encoder_val, X_decoder_val], y_decoder_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhRcSt1TmdEK",
        "outputId": "d06b83e2-9adc-405b-d30d-b4d5bba3c08d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2360.8167 - percentage_deviation: 336077.3750 - val_loss: 1552.6506 - val_percentage_deviation: 59.7886\n",
            "Epoch 2/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1384.3188 - percentage_deviation: 764483.4375 - val_loss: 1015.3453 - val_percentage_deviation: 42.8330\n",
            "Epoch 3/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 914.3341 - percentage_deviation: 1891396.0000 - val_loss: 705.1210 - val_percentage_deviation: 36.9907\n",
            "Epoch 4/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 644.3607 - percentage_deviation: 2615717.0000 - val_loss: 528.2434 - val_percentage_deviation: 33.5132\n",
            "Epoch 5/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 498.2753 - percentage_deviation: 1551452.8750 - val_loss: 419.7078 - val_percentage_deviation: 31.2381\n",
            "Epoch 6/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 395.2415 - percentage_deviation: 2325471.0000 - val_loss: 339.6247 - val_percentage_deviation: 28.7451\n",
            "Epoch 7/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 320.0963 - percentage_deviation: 3976494.0000 - val_loss: 286.7998 - val_percentage_deviation: 26.7544\n",
            "Epoch 8/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 271.2166 - percentage_deviation: 1652903.0000 - val_loss: 247.8942 - val_percentage_deviation: 25.0866\n",
            "Epoch 9/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 236.5167 - percentage_deviation: 2827507.7500 - val_loss: 216.6535 - val_percentage_deviation: 23.2808\n",
            "Epoch 10/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 202.9856 - percentage_deviation: 3108589.5000 - val_loss: 189.9834 - val_percentage_deviation: 21.3016\n",
            "Epoch 11/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 179.4765 - percentage_deviation: 2901331.5000 - val_loss: 167.0490 - val_percentage_deviation: 19.7278\n",
            "Epoch 12/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 158.4423 - percentage_deviation: 1922306.1250 - val_loss: 146.1951 - val_percentage_deviation: 17.8676\n",
            "Epoch 13/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 140.8529 - percentage_deviation: 3119886.2500 - val_loss: 127.5652 - val_percentage_deviation: 16.2854\n",
            "Epoch 14/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 120.8980 - percentage_deviation: 1113026.1250 - val_loss: 111.0608 - val_percentage_deviation: 14.8171\n",
            "Epoch 15/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 101.5997 - percentage_deviation: 2430967.7500 - val_loss: 95.1786 - val_percentage_deviation: 13.1918\n",
            "Epoch 16/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 88.7963 - percentage_deviation: 1611021.6250 - val_loss: 80.7747 - val_percentage_deviation: 11.9035\n",
            "Epoch 17/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 73.5565 - percentage_deviation: 3167422.7500 - val_loss: 69.1493 - val_percentage_deviation: 10.6352\n",
            "Epoch 18/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 60.9546 - percentage_deviation: 3692017.5000 - val_loss: 59.1694 - val_percentage_deviation: 9.2953\n",
            "Epoch 19/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 51.6431 - percentage_deviation: 1079701.5000 - val_loss: 50.7855 - val_percentage_deviation: 8.5476\n",
            "Epoch 20/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 45.1744 - percentage_deviation: 2984372.7500 - val_loss: 43.4121 - val_percentage_deviation: 7.5294\n",
            "Epoch 21/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 38.5171 - percentage_deviation: 2187523.2500 - val_loss: 37.3178 - val_percentage_deviation: 6.8652\n",
            "Epoch 22/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 33.9430 - percentage_deviation: 1217707.5000 - val_loss: 31.9947 - val_percentage_deviation: 6.1787\n",
            "Epoch 23/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.9380 - percentage_deviation: 1677121.3750 - val_loss: 27.4846 - val_percentage_deviation: 5.5779\n",
            "Epoch 24/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 23.3631 - percentage_deviation: 1748275.1250 - val_loss: 23.6525 - val_percentage_deviation: 5.0836\n",
            "Epoch 25/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 20.8189 - percentage_deviation: 1462723.2500 - val_loss: 20.4303 - val_percentage_deviation: 4.6091\n",
            "Epoch 26/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.2025 - percentage_deviation: 1202318.6250 - val_loss: 17.6217 - val_percentage_deviation: 4.2440\n",
            "Epoch 27/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 15.2513 - percentage_deviation: 819323.1875 - val_loss: 15.1995 - val_percentage_deviation: 3.8618\n",
            "Epoch 28/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 12.9839 - percentage_deviation: 285506.3438 - val_loss: 13.1406 - val_percentage_deviation: 3.5299\n",
            "Epoch 29/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.0195 - percentage_deviation: 1270945.7500 - val_loss: 11.4134 - val_percentage_deviation: 3.2936\n",
            "Epoch 30/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.6459 - percentage_deviation: 1111546.6250 - val_loss: 9.8616 - val_percentage_deviation: 2.9911\n",
            "Epoch 31/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.2959 - percentage_deviation: 694299.8125 - val_loss: 8.5883 - val_percentage_deviation: 2.8017\n",
            "Epoch 32/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.8657 - percentage_deviation: 1198610.3750 - val_loss: 7.4796 - val_percentage_deviation: 2.6409\n",
            "Epoch 33/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.3197 - percentage_deviation: 647244.6875 - val_loss: 6.5178 - val_percentage_deviation: 2.3908\n",
            "Epoch 34/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.2804 - percentage_deviation: 542815.3750 - val_loss: 5.7043 - val_percentage_deviation: 2.2435\n",
            "Epoch 35/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.7151 - percentage_deviation: 987350.0000 - val_loss: 5.0011 - val_percentage_deviation: 2.1197\n",
            "Epoch 36/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.6873 - percentage_deviation: 422776.9375 - val_loss: 4.3950 - val_percentage_deviation: 1.9720\n",
            "Epoch 37/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3395 - percentage_deviation: 761145.1875 - val_loss: 3.9056 - val_percentage_deviation: 1.9398\n",
            "Epoch 38/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8209 - percentage_deviation: 650804.0000 - val_loss: 3.4390 - val_percentage_deviation: 1.7845\n",
            "Epoch 39/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4134 - percentage_deviation: 1010256.0000 - val_loss: 3.0435 - val_percentage_deviation: 1.7177\n",
            "Epoch 40/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1686 - percentage_deviation: 255377.7969 - val_loss: 2.6758 - val_percentage_deviation: 1.5977\n",
            "Epoch 41/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.2117 - percentage_deviation: 400968.7812 - val_loss: 2.3932 - val_percentage_deviation: 1.5497\n",
            "Epoch 42/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 1.8902 - percentage_deviation: 276043.4062 - val_loss: 2.1398 - val_percentage_deviation: 1.5056\n",
            "Epoch 43/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 1.7539 - percentage_deviation: 421847.5938 - val_loss: 1.9097 - val_percentage_deviation: 1.4433\n",
            "Epoch 44/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 1.5683 - percentage_deviation: 372551.1875 - val_loss: 1.6836 - val_percentage_deviation: 1.3238\n",
            "Epoch 45/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 1.1066 - percentage_deviation: 590898.2500 - val_loss: 1.5330 - val_percentage_deviation: 1.3033\n",
            "Epoch 46/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.1285 - percentage_deviation: 704744.2500 - val_loss: 1.3615 - val_percentage_deviation: 1.2171\n",
            "Epoch 47/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0865 - percentage_deviation: 573872.7500 - val_loss: 1.2159 - val_percentage_deviation: 1.2392\n",
            "Epoch 48/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.9341 - percentage_deviation: 115300.0156 - val_loss: 1.0966 - val_percentage_deviation: 1.1463\n",
            "Epoch 49/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7776 - percentage_deviation: 334622.0938 - val_loss: 0.9952 - val_percentage_deviation: 1.1352\n",
            "Epoch 50/50\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.7116 - percentage_deviation: 225957.0781 - val_loss: 0.9022 - val_percentage_deviation: 1.0848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fe54b4e1780>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training curve plotter"
      ],
      "metadata": {
        "id": "bUYZIX8nCQkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder model for inference\n",
        "encoder_inputs = model.input[0]  # Input of the encoder\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # LSTM layer outputs\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Define the decoder model for inference\n",
        "decoder_inputs = model.input[1]  # Input of the decoder\n",
        "\n",
        "# LSTM layer\n",
        "decoder_state_input_h = Input(shape=(LSTM_hidden_dim,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_hidden_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Function to generate predictions\n",
        "def predict_sequence(encoder_model, decoder_model, input_seq, num_features, prediction_steps):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1 with only the start character\n",
        "    target_seq = np.zeros((1, 1, num_features))\n",
        "\n",
        "    # Populate the first feature of target sequence with the start character\n",
        "    # target_seq[0, 0, feature_index] = value  # If you have a specific start value\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    decoded_sequence = []\n",
        "    for _ in range(prediction_steps):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Store the prediction\n",
        "        decoded_sequence.append(output_tokens[0, 0, :])\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_features))\n",
        "        target_seq[0, 0, :num_decoder_features] = output_tokens[0, 0, :]\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return np.array(decoded_sequence)\n",
        "\n",
        "# Example usage\n",
        "input_seq = np.array([[[6,27,0,27.5,-79,25],[6,27,6,28.5,-79,25],[6,27,6,29.5,-79,25],[6,27,6,30.5,-79,25],[6,27,6,31.5,-78,25],[6,27,6,32.5,-77,25]]])  # Example input\n",
        "print(type(input_seq))\n",
        "prediction_steps = 5  # Number of future steps to predict\n",
        "predicted_sequence = predict_sequence(encoder_model, decoder_model, input_seq, num_features, prediction_steps)\n",
        "print(predicted_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6exoQNjVXfTB",
        "outputId": "701be431-248d-4fa6-c430-9639997d94ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "[[ 12.630088  -14.233355    6.0046463]\n",
            " [  6.4204288  -8.277024    3.6679015]\n",
            " [  6.2192583  -5.4994597   3.0940323]\n",
            " [  4.642462   -3.4300992   2.596946 ]\n",
            " [  3.2664518  -2.3475296   1.3877218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference model for predictions\n",
        "encoder_model = Model(encoder_inputs, encoder_states) # Model() extracts features from the trained model\n",
        "\n",
        "# decoder inference model, unlike training model, allows step-by-step sequence generation\n",
        "decoder_state_input_h = Input(shape=(6,))\n",
        "decoder_state_input_c = Input(shape=(6,))\n",
        "# decoder states of previous timestep\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# decoder takes in the decoder input, as well as the previous state in initialization\n",
        "# produces lstm output and updated states\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Function to generate predictions\n",
        "def predict_sequence(encoder_model, decoder_model, input_seq, num_features, prediction_steps):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = Input(shape=(None, num_features))\n",
        "\n",
        "\n",
        "    decoded_sequence = []\n",
        "    for _ in range(prediction_steps):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        decoded_sequence.append(output_tokens[0, 0, :])\n",
        "        target_seq = output_tokens[:, -1:, :]\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return np.array(decoded_sequence)\n",
        "\n"
      ],
      "metadata": {
        "id": "v4E7jfWnmnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = np.array([[[6, 27, 0, 27.5, -79, 25], [6, 27, 0, 28.5, -79, 25]]])  # Shape (1, 1, 6)\n",
        "prediction_steps = 10  # Number of points to predict\n",
        "predictions = predict_sequence(encoder_model, decoder_model, input_seq, num_features, prediction_steps)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "nHPAWgYRV_qR",
        "outputId": "11bc7b9f-ce0a-4384-e9a1-fed6f65478e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-756b819acab5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape (1, 1, 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprediction_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# Number of points to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a4a791ce4971>\u001b[0m in \u001b[0;36mpredict_sequence\u001b[0;34m(encoder_model, decoder_model, input_seq, num_features, prediction_steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdecoded_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdecoded_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         msg = (\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizer"
      ],
      "metadata": {
        "id": "sNnVVfYZCT_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}